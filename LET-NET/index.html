<!doctype html>
<html lang="en" xmlns="http://www.w3.org/1999/html">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="Accelerated Coordinate Encoding: Learning to Relocalize in Minutes using RGB and Poses">

        <!--Facebook preview-->
        <meta property="og:image" content="https://nianticlabs.github.io/ace/assets/social_card.png">
        <meta property="og:type" content="website"/>
        <meta property="og:url" content="https://nianticlabs.github.io/ace/"/>
        <meta property="og:title" content="Accelerated Coordinate Encoding: Learning to Relocalize in Minutes using RGB and Poses"/>
        <meta property="og:description" content="Niantic's ACE visual relocaliser creates a neural map of a place with unprecedented speed, yet offer state-of-the-art camera pose accuracy. A CVPR 2023 (Highlight)"/>

        <!--Twitter preview-->
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="twitter:title" content="Accelerated Coordinate Encoding: Learning to Relocalize in Minutes using RGB and Poses" />
        <meta name="twitter:description" content="Niantic's ACE visual relocaliser creates a neural map of a place with unprecedented speed, yet offer state-of-the-art camera pose accuracy. A CVPR 2023 (Highlight)"/>
        <meta name="twitter:image" content="https://nianticlabs.github.io/ace/assets/social_card.png">

        <title>ACE: Accelerated Coordinate Encoding</title>
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css"
            rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65"
            crossorigin="anonymous">

        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
              crossorigin="anonymous">

        <link href="style.css" rel="stylesheet">
        <link rel="icon" href="assets/fav_icon.png">
    </head>
    <body>

        <header class="mt-4 d-none d-md-block">
            <video playsinline="playsinline" autoplay="autoplay" muted="muted">
                <source src="assets/header_ace_cards.mp4" type="video/mp4">
            </video>
        </header>

        <div class="container">
            <div class="row text-center">
                <h1 class="mt-3">Accelerated Coordinate Encoding:</h1>
                <h3>Learning to Relocalize in Minutes using RGB and Poses</h3>
                <h4>CVPR 2023 (Highlight)</h4>
            </div>
            <div class="row text-center">
                <div class="col-md-12">
                    <h4>
                        <a href="https://ebrach.github.io/"><nobr>Eric Brachmann<sup>1</sup></nobr></a> &emsp;
                        <a href="https://scholar.google.it/citations?user=r7osSm0AAAAJ&hl=en"><nobr>Tommaso Cavallari<sup>1</sup></nobr></a> &emsp;
                        <a href="https://www.robots.ox.ac.uk/~victor/"><nobr>Victor Adrian Prisacariu<sup>1,2</sup></nobr></a> &emsp;
                    </h4>
                    <sup>1</sup>Niantic&nbsp;&nbsp;&nbsp;<sup>2</sup><nobr>University of Oxford&nbsp;&nbsp;&nbsp;</nobr><br>
                </div>
                <div class="col-md-12 mt-3">
                    <a href="https://arxiv.org/abs/2305.14059" class="btn btn-secondary btn-sm" target="_blank"><i class="fa-solid fa-file-pdf"></i>&nbsp;&nbsp;arXiv</a>
                    <a href="https://nianticlabs.com/news/research-ace" target="_blank" class="btn btn-secondary btn-sm"><i class="fa-solid fa-newspaper"></i>&nbsp;&nbsp;Blog</a>
                    <a href="https://www.youtube.com/watch?v=eDRBolkokC0" target="_blank" class="btn btn-secondary btn-sm"><i class="fa-brands fa-youtube"></i>&nbsp;&nbsp;Video</a>
                    <a href="https://github.com/nianticlabs/ace" target="_blank" class="btn btn-secondary btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;Code</a>
                    <a href="#dataset" class="btn btn-secondary btn-sm"><i class="fa-solid fa-images"></i>&nbsp;&nbsp;Dataset</a>

                    <a href="#citation" class="btn btn-secondary btn-sm"><i class="fa-solid fa-file"></i>&nbsp;&nbsp;BibTeX</a>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-0 col-md-2"></div>
                <div class="col-sm-12 col-md-8">
                    <h3 class="mt-5">Abstract</h3>
                    <hr/>
                    <p>
                        Learning-based visual relocalizers exhibit leading pose accuracy, but require hours or days of training. Since
                        training needs to happen on each new scene again, long training times make learning-based relocalization
                        impractical for most applications, despite its promise of high accuracy. In this paper we show how such a system
                        can actually achieve the same accuracy in less than 5 minutes. We start from the obvious: a relocalization network
                        can be split in a scene-agnostic feature backbone, and a scene-specific prediction head. Less obvious: using an MLP
                        prediction head allows us to optimize across thousands of view points simultaneously in each single training
                        iteration. This leads to stable and extremely fast convergence. Furthermore, we substitute effective but slow end-to-end
                        training using a robust pose solver with a curriculum over a reprojection loss. Our approach does not require
                        privileged knowledge, such a depth maps or a 3D model, for speedy training. Overall, our approach is up to 300x
                        faster in mapping than state-of-the-art scene coordinate regression, while keeping accuracy on par.
                    </p>

                    <h3 class="mt-5">Results</h3>
                    <hr class="hr"/>
                    <p>
                        We learn a scene map from a set of posed RGB images by minimizing the reprojection error.
                        ACE compiles the scene into 4MB worth of MLP weights during 5 minutes on a single consumer-grade
                        GPU. To Relocalise, we pass a query frame through the ACE network to obtain image-to-scene
                        correspondences followed by RANSAC+PnP.
                    </p>
                    <p>
                        Below we show a sample of scenes from the datasets in our paper. <b>Use the controls to switch
                        between scenes.</b>
                    </p>

                    <div id="aceTeaser" class="carousel slide" data-bs-ride="false">
                        <div class="carousel-indicators">
                            <button type="button" data-bs-target="#aceTeaser" data-bs-slide-to="0" class="active" aria-current="true" aria-label="Slide 1"></button>
                            <button type="button" data-bs-target="#aceTeaser" data-bs-slide-to="1" aria-label="Slide 2"></button>
                            <button type="button" data-bs-target="#aceTeaser" data-bs-slide-to="2" aria-label="Slide 3"></button>
                            <button type="button" data-bs-target="#aceTeaser" data-bs-slide-to="3" aria-label="Slide 4"></button>
                            <button type="button" data-bs-target="#aceTeaser" data-bs-slide-to="4" aria-label="Slide 5"></button>
                            <button type="button" data-bs-target="#aceTeaser" data-bs-slide-to="5" aria-label="Slide 6"></button>
                            <button type="button" data-bs-target="#aceTeaser" data-bs-slide-to="6" aria-label="Slide 7"></button>
                            <button type="button" data-bs-target="#aceTeaser" data-bs-slide-to="7" aria-label="Slide 8"></button>
                        </div>
                        <div class="carousel-inner">
                            <div class="carousel-item active">
                                <video class="w-100" autoplay loop muted>
                                    <source src="assets/carousel/wayspots_squarebench_small.mp4" type="video/mp4" />
                                </video>
                                <div class="carousel-caption">
                                    <h5>Wayspots - Square Bench</h5>
                                </div>
                            </div>
                            <div class="carousel-item">
                                <video class="w-100" autoplay loop muted>
                                    <source src="assets/carousel/7scenes_heads_small.mp4" type="video/mp4" />
                                </video>
                                <div class="carousel-caption">
                                    <h5>7Scenes - Heads</h5>
                                </div>
                            </div>
                            <div class="carousel-item">
                                <video class="w-100" autoplay loop muted>
                                    <source src="assets/carousel/12scenes_office2_5b_small.mp4" type="video/mp4" />
                                </video>
                                <div class="carousel-caption">
                                    <h5>12Scenes - Office2 - 5b</h5>
                                </div>
                            </div>
                            <div class="carousel-item">
                                <video class="w-100" autoplay loop muted>
                                    <source src="assets/carousel/Cambridge_ShopFacade_small.mp4" type="video/mp4" />
                                </video>
                                <div class="carousel-caption">
                                    <h5>Cambridge - Shop Facade</h5>
                                </div>
                            </div>
                            <div class="carousel-item">
                                <video class="w-100" autoplay loop muted>
                                    <source src="assets/carousel/wayspots_therock_small.mp4" type="video/mp4" />
                                </video>
                                <div class="carousel-caption">
                                    <h5>Wayspots - The Rock</h5>
                                </div>
                            </div>
                            <div class="carousel-item">
                                <video class="w-100" autoplay loop muted>
                                    <source src="assets/carousel/7scenes_stairs_small.mp4" type="video/mp4" />
                                </video>
                                <div class="carousel-caption">
                                    <h5>7Scenes - Stairs</h5>
                                </div>
                            </div>
                            <div class="carousel-item">
                                <video class="w-100" autoplay loop muted>
                                    <source src="assets/carousel/12scenes_apt1_kitchen_small.mp4" type="video/mp4" />
                                </video>
                                <div class="carousel-caption">
                                    <h5>12Scenes - Apt1 - Kitchen</h5>
                                </div>
                            </div>
                            <div class="carousel-item">
                                <video class="w-100" autoplay loop muted>
                                    <source src="assets/carousel/Cambridge_OldHospital_small.mp4" type="video/mp4" />
                                </video>
                                <div class="carousel-caption">
                                    <h5>Cambridge - Old Hospital</h5>
                                </div>
                            </div>
                        </div>
                        <button class="carousel-control-prev" type="button" data-bs-target="#aceTeaser" data-bs-slide="prev">
                            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                            <span class="visually-hidden">Previous</span>
                        </button>
                        <button class="carousel-control-next" type="button" data-bs-target="#aceTeaser" data-bs-slide="next">
                            <span class="carousel-control-next-icon" aria-hidden="true"></span>
                            <span class="visually-hidden">Next</span>
                        </button>
                    </div>
                    <p>
                        ACE is deployed as part of Niantic's
                        <a href="https://lightship.dev/products/vps">Lightship Visual Positioning System (VPS)</a>
                        to offer relocalisation at almost 200,000 places world-wide.
                    </p>

                    <h3 class="mt-5">Comparison to DSAC*</h3>
                    <hr class="hr"/>
                    <p>
                        ACE builds on the previously leading learning-based relocaliser
                        <a href="https://github.com/vislearn/dsacstar">DSAC*</a> but maps a scene up to 300x faster.
                        ACE takes a process that took hours or days for each new scene, and makes it happen in minutes.
                        In terms of relocalisation accuracy, ACE is on par with DSAC*, if not slightly superior.
                    </p>
                    <video class="w-100" autoplay loop muted controls>
                        <source src="assets/ace_vs_dsac_wayspots_squarebench.mp4" type="video/mp4" />
                    </video>

                    <h3 class="mt-5">Why Is ACE So Much Faster?</h3>
                    <hr class="hr"/>
                    <p>
                        DSAC* optimises the scene reprojection error one mapping image at a time. One image provides a
                        lot of pixels for learning, but their reprojection errors are highly correlated. The network
                        prediction for a pixel and its neighbour are almost the same - so are their losses and their
                        gradients.
                    </p>
                    <p>
                        ACE revolves around the idea of optimising the map across all mapping images, simultaneously. We
                        split the regression network into a convolutional feature backbone and a MLP head. The backbone is
                        pre-trained and extracts high-dimensional features for all mapping images. Since the MLP head
                        needs no spatial context, we can create batches of a random selection of features during training.
                        This de-correlates gradients within a batch and allows for stable optimization with very high
                        learning rates.
                    </p>
                    <video class="w-100 mb-4" autoplay loop muted>
                        <source src="assets/training_ani.mp4" type="video/mp4" />
                    </video>
                    <p>
                        In fact, the resulting optimization is so stable that we cain train ACE considerably faster than 5
                        minutes to obtain results that are still usable. Below, we show a run of ACE with <b>10 seconds</b>
                        training time (excluding 20s data preparation).
                    </p>
                    <video class="w-100" autoplay loop muted>
                        <source src="assets/realtime_7scenes_chess.mp4" type="video/mp4" />
                    </video>

                    <h3 class="mt-5">ACE on Larger Scenes</h3>
                    <hr class="hr"/>
                    <p>
                        ACE fares fairly well in bigger outdoor scenes. Naturally, the 4MB memory footprint and short
                        mapping time pose some restrictions on what it can do. As a simple strategy, one can split a
                        larger scene into smaller chunks and train one ACE model per chunk. For relocalisation, we let
                        each ACE model estimate a pose independently and choose the one with the highest inlier count.
                    </p>
                    <p>
                        Using an ACE ensemble naturally increases map size and mapping time. Conveniently, models can
                        be trained in parallel if multiple GPUs are available.
                    </p>
                    <video class="w-100" autoplay loop muted controls>
                        <source src="assets/poker_cambridge_stmaryschurch.mp4" type="video/mp4" />
                    </video>


                    <h3 class="mt-5" id="dataset">The Wayspots Dataset</h3>
                    <hr class="hr"/>
                    <p>
                        To demonstrate the advantages of ACE, we curated a new dataset of 10 small outdoor scenes stemming
                        from Niantic's Map-Free dataset. Each scene was scanned twice, independently by two users. Posed
                        mapping images come from real-time visual odometry on the user's phones. Depth or 3D point
                        clouds are not available. Evaluation ground truth comes from SfM.
                    </p>
                    <p>
                        The dataset follows DSAC*'s data convention. You find more information in our
                        <a href="https://github.com/nianticlabs/ace">code repository</a>.
                    </p>
                    <div class="w-100 text-center mt-3">
                        <a href="wayspots.html" class="btn btn-secondary btn-sm">To Download Page</a>
                    </div>
                    <video class="w-100 mt-3" autoplay loop muted controls>
                        <source src="assets/dataset_wayspots.mp4" type="video/mp4" />
                    </video>


                    <h3 class="mt-5" id="citation">Citation</h3>
                    <hr class="hr"/>
                    <p>
                        If you use parts of our code or our dataset, please consider citing our paper.
                    </p>
                    <pre class="w-100 user-select-all font-monospace border border-secondary bg-dark mb-5 p-2">
@inproceedings{brachmann2023ace,
    title={Accelerated Coordinate Encoding: Learning to Relocalize in Minutes using RGB and Poses},
    author={Brachmann, Eric and Cavallari, Tommaso and Prisacariu, Victor Adrian},
    booktitle={CVPR},
    year={2023},
}</pre>

                </div>
                <div class="col-sm-0 col-md-2"></div>



            </div>
        </div>

        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4"
            crossorigin="anonymous"></script>
        <!-- <script src="https://kit.fontawesome.com/746ee6bfa4.js" crossorigin="anonymous"></script> -->

        <script>
            window.addEventListener('load', videoScroll);
            window.addEventListener('scroll', videoScroll);

            function videoScroll() {

                if ( document.querySelectorAll('video[autoplay]').length > 0) {

                    var windowHeight = window.innerHeight,
                    videoEl = document.querySelectorAll('video[autoplay]');

                    for (var i = 0; i < videoEl.length; i++) {

                        var thisVideoEl = videoEl[i],
                            videoHeight = thisVideoEl.clientHeight,
                            videoClientRect = thisVideoEl.getBoundingClientRect().top;

                        if ( (thisVideoEl.parentNode.classList.contains('carousel-item') && thisVideoEl.parentNode.classList.contains('active')) || (thisVideoEl.parentNode.nodeName === 'DIV' && !thisVideoEl.parentNode.classList.contains('carousel-item') )) {
                            if ( videoClientRect <= ( (windowHeight) - (videoHeight*.8) ) && videoClientRect >= ( 0 - ( videoHeight*.2 ) ) ) {
                                thisVideoEl.play();
                            } else {
                                thisVideoEl.pause();
                            }
                        }
                    }
                }
            }
        </script>
    </body>
</html>
